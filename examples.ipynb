{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# US Jobs Data Project\n",
    "\n",
    "This project downloads and collates/curates data from the US Bureau of Labor Statistics (BLS) using data from the Occupational Employment Statistics (OES) survey. \n",
    "\n",
    "The purpose of this project is to highlight and make accessible the excellent work of the people at BLS.\n",
    "\n",
    "## About the BLS OES dataset\n",
    "\n",
    "The OES dataset is remarkable, containing data for around 1,000 different occupations at national, state, and city levels. Data on numbers of jobs and pay statistics are collected.\n",
    "\n",
    "The BLS does maintain an API which can be accessed by using a free access code: https://www.bls.gov/developers/home.htm.\n",
    "\n",
    "Other than the API, the data from OES is available via Excel spreadsheets from a data download page: https://www.bls.gov/oes/tables.htm \n",
    "\n",
    "The data is also available via a web interface (https://www.bls.gov/oes/current/oes_nat.htm, for example). \n",
    "\n",
    "One benefit of this project is it makes all the data from different years available in one place, easily query-able via a SQLite interface, so that the data can be looked at as a time series, which is a very compelling way to understand these kinds of economic data. \n",
    "\n",
    "## Approach\n",
    "\n",
    "My approach to collating this data is to download all of the excel data files and insert into a SQLite database.\n",
    "\n",
    "## Data consistency\n",
    "\n",
    "The main challenge to interpreting these data as a time series is changing data collection methods over time. For example, occupation codes changed in 2011 from using SOC 2000 codes to SOC 2010 codes. This can be addressed using the crosswalk provided by BLS. Other consistency issues are more difficult. For example Grand Rapids, MI seems to have been redistricted in 2015 as job numbers underwent a step change.\n",
    "\n",
    "Historical records go back to 1988, but changing industry and area codes make curation difficult. \n",
    "\n",
    "The data downloaded encompassed by this project is as follows: state and national data is consistent back to 2001, while metro data goes back to 2005 when metro area codes changed. It may be possible to create a crosswalk to previous metro codes, which will be explored in the future.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using this project\n",
    "\n",
    "The first thing you will need to do is to either download or construct the database.\n",
    "\n",
    "## Download completed database\n",
    "\n",
    "The completed SQLite database file is available for download from Dropbox: https://www.dropbox.com/scl/fi/ehi3ftpr9yqhr38glxz4f/OE.db?rlkey=ugfaf9z1imvgfzr4n9orx4snw&dl=0\n",
    "\n",
    "## Build database\n",
    "\n",
    "The database may also be constructed as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find a version that satisfies the requirement jupiter (from versions: none)\n",
      "ERROR: No matching distribution found for jupiter\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\python312\\lib\\site-packages (2.2.1)\n",
      "Requirement already satisfied: openpyxl in c:\\python312\\lib\\site-packages (3.1.2)\n",
      "Requirement already satisfied: xlrd in c:\\python312\\lib\\site-packages (2.0.1)\n"
     ]
    }
   ],
   "source": [
    "# Needed packages\n",
    "!pip install pandas openpyxl xlrd jupiterlab notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Note\n",
    "The following code is not needed if you download database. There is still work to be done, given that BLS thinks, sometimes, that I am a bot and block the downloading of the files. One solutions is to manually download all the zip files, organize them into 4 folders, change the name of the zip file and run the codes (now the downloading capabilities of the code are turn off, but you can make them available again)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !python download_and_save.py ## downloads and saves the Excel data files from the BLS website\n",
    "# !python build_database_OE.py ## makes the SQLite database and inserts some necessary code tables\n",
    "# !python get_OE_data_from_xlsx.py ## extracts the data from the Excel file and puts in to the SQLite database\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Querying the database\n",
    "\n",
    "The database is structured around the series code for the OES survey: https://www.bls.gov/help/hlpforma.htm\n",
    "\n",
    "The series code has the following components:\n",
    "\n",
    "+ Area code\n",
    "    + What area (national, state or metro) is the job in.\n",
    "+ Industry code\n",
    "    + What industry the job exists in.\n",
    "+ Occupation code\n",
    "    + The occupation the job exists in.\n",
    "    + Occupation is distinct from industry, for example on might be an accountant (occupation) in the construction industry (industry).\n",
    "+ Data type code\n",
    "    + What quantity are we measuring (number of jobs, median pay, etc).\n",
    "\n",
    "The full series code specifies each of these things and resides in the `series_code` table. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import pandas as pd \n",
    "\n",
    "conn = sqlite3.connect('OE.db') ##\n",
    "query = \"\"\"SELECT year, value, industry_code, occupation_code, data_type\n",
    "FROM value v --table containing values\n",
    "JOIN series_code sc --table containing series_codes\n",
    "ON sc.code = v.series_code\n",
    "WHERE sc.occupation_code IN ('000000','110000','130000','150000', '170000', '190000','210000'\n",
    ",'230000', '250000', '270000', '290000', '310000', '330000', '350000', '370000', '390000',\n",
    "'410000', '430000', '450000', '470000', '490000', '510000', '530000')\n",
    "AND sc.area_code = 'N0000000' --area_code for USA\n",
    "AND sc.industry_code in('000000', '000001', '31--34')\n",
    "AND sc.data_type in ('01', '03', '04', '13')\n",
    "ORDER BY 1 ASC;\n",
    "\"\"\"\n",
    "df = pd.read_sql_query(query, conn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>value</th>\n",
       "      <th>industry_code</th>\n",
       "      <th>occupation_code</th>\n",
       "      <th>data_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2011</td>\n",
       "      <td>21.150000</td>\n",
       "      <td>000001</td>\n",
       "      <td>000000</td>\n",
       "      <td>03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2011</td>\n",
       "      <td>47.175333</td>\n",
       "      <td>000001</td>\n",
       "      <td>110000</td>\n",
       "      <td>03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2011</td>\n",
       "      <td>31.404828</td>\n",
       "      <td>000001</td>\n",
       "      <td>130000</td>\n",
       "      <td>03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2011</td>\n",
       "      <td>38.337647</td>\n",
       "      <td>000001</td>\n",
       "      <td>150000</td>\n",
       "      <td>03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2011</td>\n",
       "      <td>35.904857</td>\n",
       "      <td>000001</td>\n",
       "      <td>170000</td>\n",
       "      <td>03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2387</th>\n",
       "      <td>2023</td>\n",
       "      <td>44180.833333</td>\n",
       "      <td>31--34</td>\n",
       "      <td>450000</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2388</th>\n",
       "      <td>2023</td>\n",
       "      <td>49341.800000</td>\n",
       "      <td>31--34</td>\n",
       "      <td>470000</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2389</th>\n",
       "      <td>2023</td>\n",
       "      <td>55796.382979</td>\n",
       "      <td>31--34</td>\n",
       "      <td>490000</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2390</th>\n",
       "      <td>2023</td>\n",
       "      <td>46135.728155</td>\n",
       "      <td>31--34</td>\n",
       "      <td>510000</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2391</th>\n",
       "      <td>2023</td>\n",
       "      <td>55847.500000</td>\n",
       "      <td>31--34</td>\n",
       "      <td>530000</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2392 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      year         value industry_code occupation_code data_type\n",
       "0     2011     21.150000        000001          000000        03\n",
       "1     2011     47.175333        000001          110000        03\n",
       "2     2011     31.404828        000001          130000        03\n",
       "3     2011     38.337647        000001          150000        03\n",
       "4     2011     35.904857        000001          170000        03\n",
       "...    ...           ...           ...             ...       ...\n",
       "2387  2023  44180.833333        31--34          450000        13\n",
       "2388  2023  49341.800000        31--34          470000        13\n",
       "2389  2023  55796.382979        31--34          490000        13\n",
       "2390  2023  46135.728155        31--34          510000        13\n",
       "2391  2023  55847.500000        31--34          530000        13\n",
       "\n",
       "[2392 rows x 5 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('out.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
